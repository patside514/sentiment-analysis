{'role': 'assistant', 'content': '<function_calls>\n<create-file file_path="README.md">\n# 🚀 Social Media Sentiment Analysis Tool\n\nUne application SaaS complète en Python pour analyser le sentiment des réseaux sociaux à partir de Twitter, Facebook et Google Reviews.\n\n## 📋 Fonctionnalités\n\n- **Extraction multi-plateformes** : Twitter, Facebook, Google Reviews\n- **Analyse de sentiment** : TextBlob + Transformers (modèles multilingues)\n- **Extraction de mots-clés** : TF-IDF, fréquence, TextRank, combinaison\n- **Visualisations** : Graphiques matplotlib, nuages de mots, tableaux de bord\n- **Rapports complets** : HTML, CSV, JSON\n- **Interface CLI** : Facile à utiliser avec options détaillées\n- **Support multilingue** : Français et Anglais avec détection automatique\n\n## 🛠️ Installation\n\n### Prérequis\n\n- Python 3.10 ou supérieur\n- pip (gestionnaire de paquets Python)\n\n### Installation rapide\n\n```bash\n# Cloner le dépôt\ngit clone https://github.com/votre-repo/social-media-sentiment-analyzer.git\ncd social-media-sentiment-analyzer\n\n# Créer un environnement virtuel\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# ou\nvenv\\Scripts\\activate  # Windows\n\n# Installer les dépendances\npip install -r requirements.txt\n\n# Télécharger les données NLTK\npython -c "import nltk; nltk.download(\'punkt\'); nltk.download(\'stopwords\')"\n\n# Installer spaCy models (optionnel mais recommandé)\npython -m spacy download fr_core_news_sm\npython -m spacy download en_core_web_sm\n```\n\n### Configuration des API\n\n1. **Copier le fichier d\'exemple** :\n```bash\ncp .env.example .env\n```\n\n2. **Configurer les clés API** :\n   - **Twitter** : Créez une application sur https://developer.twitter.com/\n   - **Facebook** : Obtenez un token d\'accès sur https://developers.facebook.com/\n   - **Google** : Créez une clé API sur https://console.cloud.google.com/\n\n3. **Éditer le fichier `.env`** avec vos clés API\n\n## 🚀 Utilisation\n\n### Commande de base\n\n```bash\npython app.py --service "Uber" --source "twitter" --days 30\n```\n\n### Options avancées\n\n```bash\npython app.py --service "Netflix" \\\n              --source "facebook" \\\n              --days 15 \\\n              --max-posts 200 \\\n              --format html \\\n              --language fr \\\n              --sentiment-model transformers \\\n              --keyword-method combined\n```\n\n### Paramètres disponibles\n\n| Paramètre | Description | Défaut |\n|-----------|-------------|---------|\n| `--service, -s` | Nom du service/marque à analyser (obligatoire) | - |\n| `--source, -src` | Source (twitter/facebook/google_reviews) | twitter |\n| `--days, -d` | Nombre de jours à analyser (1-60) | 30 |\n| `--max-posts, -m` | Nombre maximum de posts (50-500) | 500 |\n| `--output-dir, -o` | Répertoire de sortie | auto |\n| `--format, -f` | Format (csv/json/html/all) | all |\n| `--language, -l` | Langue (auto/fr/en) | auto |\n| `--sentiment-model, -sm` | Modèle de sentiment | auto |\n| `--keyword-method, -km` | Méthode d\'extraction | combined |\n| `--verbose, -v` | Mode verbeux | False |\n| `--quiet, -q` | Mode silencieux | False |\n| `--dry-run` | Simulation sans extraction | False |\n\n## 📊 Exemples d\'utilisation\n\n### Analyse de sentiment pour Uber sur Twitter\n\n```bash\npython app.py --service "Uber" --source "twitter" --days 30 --max-posts 500\n```\n\n### Analyse détaillée avec rapport HTML\n\n```bash\npython app.py --service "Airbnb" --source "google_reviews" --days 30 --format html --verbose\n```\n\n### Analyse multi-sources\n\n```bash\n# Twitter\npython app.py -s "Netflix" -src "twitter" -d 30 -m 300\n\n# Facebook\npython app.py -s "Netflix" -src "facebook" -d 30 -m 300\n\n# Google Reviews\npython app.py -s "Netflix" -src "google_reviews" -d 30 -m 300\n```\n\n## 📈 Sorties générées\n\nL\'application génère plusieurs types de fichiers :\n\n### Fichiers de données\n- `raw_data_[timestamp].csv` : Données brutes extraites\n- `processed_data_[timestamp].csv` : Données nettoyées avec sentiment\n- `keywords_[timestamp].csv` : Mots-clés extraits\n\n### Visualisations\n- `sentiment_pie_chart.png` : Camembert des sentiments\n- `sentiment_bar_chart.png` : Graphique en barres\n- `sentiment_trend_chart.png` : Tendances temporelles\n- `keyword_frequency_chart.png` : Fréquence des mots-clés\n- `keyword_score_chart.png` : Score de pertinence\n- `analysis_dashboard.png` : Tableau de bord complet\n\n### Nuages de mots\n- `keywords_wordcloud.png` : Nuage de mots général\n- `positive_sentiment_wordcloud.png` : Nuage de mots positifs\n- `negative_sentiment_wordcloud.png` : Nuage de mots négatifs\n- `neutral_sentiment_wordcloud.png` : Nuage de mots neutres\n\n### Rapports\n- `report_metadata.json` : Métadonnées de l\'analyse\n- `sentiment_summary.json` : Résumé des sentiments\n- `[service]_[source]_report_[timestamp].html` : Rapport HTML complet\n\n## 🔧 Architecture technique\n\n### Structure du projet\n\n```\nsocial-media-sentiment-analyzer/\n├── src/\n│   ├── extractors/          # Modules d\'extraction\n│   │   ├── base_extractor.py\n│   │   ├── twitter_extractor.py\n│   │   ├── facebook_extractor.py\n│   │   └── google_reviews_extractor.py\n│   ├── nlp/                 # Traitement NLP\n│   │   ├── sentiment_analyzer.py\n│   │   ├── keyword_extractor.py\n│   │   └── text_preprocessor.py\n│   ├── visualization/       # Visualisation\n│   │   ├── charts_generator.py\n│   │   ├── wordcloud_generator.py\n│   │   └── report_generator.py\n│   ├── utils/               # Utilitaires\n│   │   ├── logger.py\n│   │   ├── data_validator.py\n│   │   └── file_manager.py\n│   ├── config.py            # Configuration\n│   ├── main.py              # Orchestration principale\n│   └── cli.py               # Interface CLI\n├── data/                    # Données temporaires\n├── outputs/                 # Résultats\n├── requirements.txt         # Dépendances\n├── app.py                   # Point d\'entrée\n└── setup.py                 # Installation\n```\n\n### Technologies utilisées\n\n- **Extraction** : Tweepy, Facebook SDK, BeautifulSoup, requests\n- **NLP** : NLTK, TextBlob, spaCy, Transformers (Hugging Face)\n- **Analyse** : scikit-learn, pandas, numpy\n- **Visualisation** : matplotlib, seaborn, wordcloud\n- **Interface** : Click, colorama, tqdm\n- **Configuration** : python-dotenv\n\n## 🎯 Méthodologie\n\n### Analyse de sentiment\n\n1. **Prétraitement** : Nettoyage, normalisation, détection de langue\n2. **Modèles utilisés** :\n   - TextBlob (français/anglais)\n   - Transformers (RoBERTa multilingue)\n3. **Classification** : Positif/Négatif/Neutre avec score de confiance\n\n### Extraction de mots-clés\n\n1. **TF-IDF** : Importance relative dans le corpus\n2. **Fréquence** : Occurrences brutes\n3. **TextRank** : Algorithme basé sur PageRank\n4. **Combinaison** : Moyenne pondérée des méthodes\n\n### Validation des données\n\n- Filtrage par longueur minimale\n- Détection et suppression de spam\n- Normalisation du texte\n- Validation des métadonnées\n\n## ⚠️ Limites et considérations\n\n### API Limits\n- **Twitter** : 300 requêtes/15 minutes\n- **Facebook** : 200 requêtes/heure\n- **Google** : 100 requêtes/jour\n\n### Limitations techniques\n- Dépend des API disponibles et de leurs restrictions\n- L\'analyse de sentiment peut varier selon la qualité du texte\n- Les résultats sont indicatifs et nécessitent interprétation humaine\n\n### Considérations éthiques\n- Respect des conditions d\'utilisation des plateformes\n- Anonymisation des données personnelles\n- Usage conforme aux réglementations (GDPR, etc.)\n\n## 🔍 Dépannage\n\n### Problèmes courants\n\n**Erreur d\'authentification API**\n```bash\n# Vérifiez vos clés API dans le fichier .env\n# Assurez-vous que les clés sont actives et valides\n```\n\n**Pas de données extraites**\n```bash\n# Vérifiez le nom du service (essayez des variantes)\n# Réduisez la période ou augmentez max-posts\n# Vérifiez les limites d\'API\n```\n\n**Erreurs de dépendances**\n```bash\n# Réinstallez les dépendances\npip install -r requirements.txt --upgrade\n\n# Installez les modèles spaCy\npython -m spacy download fr_core_news_sm\npython -m spacy download en_core_web_sm\n```\n\n### Support\n\nPour les problèmes techniques :\n1. Vérifiez les logs dans `outputs/app.log`\n2. Activez le mode verbose (`--verbose`)\n3. Consultez la documentation des API\n4. Ouvrez une issue sur le dépôt GitHub\n\n## 📄 Licence\n\nCe projet est sous licence MIT. Voir le fichier LICENSE pour plus de détails.\n\n## 🤝 Contribution\n\nLes contributions sont les bienvenues ! Veuillez :\n1. Fork le projet\n2. Créer une branche pour votre fonctionnalité\n3. Commit vos changements\n4. Push vers la branche\n5. Ouvrir une Pull Request\n\n## 📞 Contact\n\nPour toute question ou suggestion :\n- Email : contact@ninjatech.ai\n- GitHub : https://github.com/ninjatech-ai\n\n---\n\n**Made with ❤️ by NinjaTech AI Team**\n</create-file>\n</function_calls>'}