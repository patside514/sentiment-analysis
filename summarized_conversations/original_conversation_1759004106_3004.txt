{'role': 'assistant', 'content': '<function_calls>\n<create-file file_path="README.md">\n# ğŸš€ Social Media Sentiment Analysis Tool\n\nUne application SaaS complÃ¨te en Python pour analyser le sentiment des rÃ©seaux sociaux Ã  partir de Twitter, Facebook et Google Reviews.\n\n## ğŸ“‹ FonctionnalitÃ©s\n\n- **Extraction multi-plateformes** : Twitter, Facebook, Google Reviews\n- **Analyse de sentiment** : TextBlob + Transformers (modÃ¨les multilingues)\n- **Extraction de mots-clÃ©s** : TF-IDF, frÃ©quence, TextRank, combinaison\n- **Visualisations** : Graphiques matplotlib, nuages de mots, tableaux de bord\n- **Rapports complets** : HTML, CSV, JSON\n- **Interface CLI** : Facile Ã  utiliser avec options dÃ©taillÃ©es\n- **Support multilingue** : FranÃ§ais et Anglais avec dÃ©tection automatique\n\n## ğŸ› ï¸ Installation\n\n### PrÃ©requis\n\n- Python 3.10 ou supÃ©rieur\n- pip (gestionnaire de paquets Python)\n\n### Installation rapide\n\n```bash\n# Cloner le dÃ©pÃ´t\ngit clone https://github.com/votre-repo/social-media-sentiment-analyzer.git\ncd social-media-sentiment-analyzer\n\n# CrÃ©er un environnement virtuel\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# ou\nvenv\\Scripts\\activate  # Windows\n\n# Installer les dÃ©pendances\npip install -r requirements.txt\n\n# TÃ©lÃ©charger les donnÃ©es NLTK\npython -c "import nltk; nltk.download(\'punkt\'); nltk.download(\'stopwords\')"\n\n# Installer spaCy models (optionnel mais recommandÃ©)\npython -m spacy download fr_core_news_sm\npython -m spacy download en_core_web_sm\n```\n\n### Configuration des API\n\n1. **Copier le fichier d\'exemple** :\n```bash\ncp .env.example .env\n```\n\n2. **Configurer les clÃ©s API** :\n   - **Twitter** : CrÃ©ez une application sur https://developer.twitter.com/\n   - **Facebook** : Obtenez un token d\'accÃ¨s sur https://developers.facebook.com/\n   - **Google** : CrÃ©ez une clÃ© API sur https://console.cloud.google.com/\n\n3. **Ã‰diter le fichier `.env`** avec vos clÃ©s API\n\n## ğŸš€ Utilisation\n\n### Commande de base\n\n```bash\npython app.py --service "Uber" --source "twitter" --days 30\n```\n\n### Options avancÃ©es\n\n```bash\npython app.py --service "Netflix" \\\n              --source "facebook" \\\n              --days 15 \\\n              --max-posts 200 \\\n              --format html \\\n              --language fr \\\n              --sentiment-model transformers \\\n              --keyword-method combined\n```\n\n### ParamÃ¨tres disponibles\n\n| ParamÃ¨tre | Description | DÃ©faut |\n|-----------|-------------|---------|\n| `--service, -s` | Nom du service/marque Ã  analyser (obligatoire) | - |\n| `--source, -src` | Source (twitter/facebook/google_reviews) | twitter |\n| `--days, -d` | Nombre de jours Ã  analyser (1-60) | 30 |\n| `--max-posts, -m` | Nombre maximum de posts (50-500) | 500 |\n| `--output-dir, -o` | RÃ©pertoire de sortie | auto |\n| `--format, -f` | Format (csv/json/html/all) | all |\n| `--language, -l` | Langue (auto/fr/en) | auto |\n| `--sentiment-model, -sm` | ModÃ¨le de sentiment | auto |\n| `--keyword-method, -km` | MÃ©thode d\'extraction | combined |\n| `--verbose, -v` | Mode verbeux | False |\n| `--quiet, -q` | Mode silencieux | False |\n| `--dry-run` | Simulation sans extraction | False |\n\n## ğŸ“Š Exemples d\'utilisation\n\n### Analyse de sentiment pour Uber sur Twitter\n\n```bash\npython app.py --service "Uber" --source "twitter" --days 30 --max-posts 500\n```\n\n### Analyse dÃ©taillÃ©e avec rapport HTML\n\n```bash\npython app.py --service "Airbnb" --source "google_reviews" --days 30 --format html --verbose\n```\n\n### Analyse multi-sources\n\n```bash\n# Twitter\npython app.py -s "Netflix" -src "twitter" -d 30 -m 300\n\n# Facebook\npython app.py -s "Netflix" -src "facebook" -d 30 -m 300\n\n# Google Reviews\npython app.py -s "Netflix" -src "google_reviews" -d 30 -m 300\n```\n\n## ğŸ“ˆ Sorties gÃ©nÃ©rÃ©es\n\nL\'application gÃ©nÃ¨re plusieurs types de fichiers :\n\n### Fichiers de donnÃ©es\n- `raw_data_[timestamp].csv` : DonnÃ©es brutes extraites\n- `processed_data_[timestamp].csv` : DonnÃ©es nettoyÃ©es avec sentiment\n- `keywords_[timestamp].csv` : Mots-clÃ©s extraits\n\n### Visualisations\n- `sentiment_pie_chart.png` : Camembert des sentiments\n- `sentiment_bar_chart.png` : Graphique en barres\n- `sentiment_trend_chart.png` : Tendances temporelles\n- `keyword_frequency_chart.png` : FrÃ©quence des mots-clÃ©s\n- `keyword_score_chart.png` : Score de pertinence\n- `analysis_dashboard.png` : Tableau de bord complet\n\n### Nuages de mots\n- `keywords_wordcloud.png` : Nuage de mots gÃ©nÃ©ral\n- `positive_sentiment_wordcloud.png` : Nuage de mots positifs\n- `negative_sentiment_wordcloud.png` : Nuage de mots nÃ©gatifs\n- `neutral_sentiment_wordcloud.png` : Nuage de mots neutres\n\n### Rapports\n- `report_metadata.json` : MÃ©tadonnÃ©es de l\'analyse\n- `sentiment_summary.json` : RÃ©sumÃ© des sentiments\n- `[service]_[source]_report_[timestamp].html` : Rapport HTML complet\n\n## ğŸ”§ Architecture technique\n\n### Structure du projet\n\n```\nsocial-media-sentiment-analyzer/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ extractors/          # Modules d\'extraction\nâ”‚   â”‚   â”œâ”€â”€ base_extractor.py\nâ”‚   â”‚   â”œâ”€â”€ twitter_extractor.py\nâ”‚   â”‚   â”œâ”€â”€ facebook_extractor.py\nâ”‚   â”‚   â””â”€â”€ google_reviews_extractor.py\nâ”‚   â”œâ”€â”€ nlp/                 # Traitement NLP\nâ”‚   â”‚   â”œâ”€â”€ sentiment_analyzer.py\nâ”‚   â”‚   â”œâ”€â”€ keyword_extractor.py\nâ”‚   â”‚   â””â”€â”€ text_preprocessor.py\nâ”‚   â”œâ”€â”€ visualization/       # Visualisation\nâ”‚   â”‚   â”œâ”€â”€ charts_generator.py\nâ”‚   â”‚   â”œâ”€â”€ wordcloud_generator.py\nâ”‚   â”‚   â””â”€â”€ report_generator.py\nâ”‚   â”œâ”€â”€ utils/               # Utilitaires\nâ”‚   â”‚   â”œâ”€â”€ logger.py\nâ”‚   â”‚   â”œâ”€â”€ data_validator.py\nâ”‚   â”‚   â””â”€â”€ file_manager.py\nâ”‚   â”œâ”€â”€ config.py            # Configuration\nâ”‚   â”œâ”€â”€ main.py              # Orchestration principale\nâ”‚   â””â”€â”€ cli.py               # Interface CLI\nâ”œâ”€â”€ data/                    # DonnÃ©es temporaires\nâ”œâ”€â”€ outputs/                 # RÃ©sultats\nâ”œâ”€â”€ requirements.txt         # DÃ©pendances\nâ”œâ”€â”€ app.py                   # Point d\'entrÃ©e\nâ””â”€â”€ setup.py                 # Installation\n```\n\n### Technologies utilisÃ©es\n\n- **Extraction** : Tweepy, Facebook SDK, BeautifulSoup, requests\n- **NLP** : NLTK, TextBlob, spaCy, Transformers (Hugging Face)\n- **Analyse** : scikit-learn, pandas, numpy\n- **Visualisation** : matplotlib, seaborn, wordcloud\n- **Interface** : Click, colorama, tqdm\n- **Configuration** : python-dotenv\n\n## ğŸ¯ MÃ©thodologie\n\n### Analyse de sentiment\n\n1. **PrÃ©traitement** : Nettoyage, normalisation, dÃ©tection de langue\n2. **ModÃ¨les utilisÃ©s** :\n   - TextBlob (franÃ§ais/anglais)\n   - Transformers (RoBERTa multilingue)\n3. **Classification** : Positif/NÃ©gatif/Neutre avec score de confiance\n\n### Extraction de mots-clÃ©s\n\n1. **TF-IDF** : Importance relative dans le corpus\n2. **FrÃ©quence** : Occurrences brutes\n3. **TextRank** : Algorithme basÃ© sur PageRank\n4. **Combinaison** : Moyenne pondÃ©rÃ©e des mÃ©thodes\n\n### Validation des donnÃ©es\n\n- Filtrage par longueur minimale\n- DÃ©tection et suppression de spam\n- Normalisation du texte\n- Validation des mÃ©tadonnÃ©es\n\n## âš ï¸ Limites et considÃ©rations\n\n### API Limits\n- **Twitter** : 300 requÃªtes/15 minutes\n- **Facebook** : 200 requÃªtes/heure\n- **Google** : 100 requÃªtes/jour\n\n### Limitations techniques\n- DÃ©pend des API disponibles et de leurs restrictions\n- L\'analyse de sentiment peut varier selon la qualitÃ© du texte\n- Les rÃ©sultats sont indicatifs et nÃ©cessitent interprÃ©tation humaine\n\n### ConsidÃ©rations Ã©thiques\n- Respect des conditions d\'utilisation des plateformes\n- Anonymisation des donnÃ©es personnelles\n- Usage conforme aux rÃ©glementations (GDPR, etc.)\n\n## ğŸ” DÃ©pannage\n\n### ProblÃ¨mes courants\n\n**Erreur d\'authentification API**\n```bash\n# VÃ©rifiez vos clÃ©s API dans le fichier .env\n# Assurez-vous que les clÃ©s sont actives et valides\n```\n\n**Pas de donnÃ©es extraites**\n```bash\n# VÃ©rifiez le nom du service (essayez des variantes)\n# RÃ©duisez la pÃ©riode ou augmentez max-posts\n# VÃ©rifiez les limites d\'API\n```\n\n**Erreurs de dÃ©pendances**\n```bash\n# RÃ©installez les dÃ©pendances\npip install -r requirements.txt --upgrade\n\n# Installez les modÃ¨les spaCy\npython -m spacy download fr_core_news_sm\npython -m spacy download en_core_web_sm\n```\n\n### Support\n\nPour les problÃ¨mes techniques :\n1. VÃ©rifiez les logs dans `outputs/app.log`\n2. Activez le mode verbose (`--verbose`)\n3. Consultez la documentation des API\n4. Ouvrez une issue sur le dÃ©pÃ´t GitHub\n\n## ğŸ“„ Licence\n\nCe projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.\n\n## ğŸ¤ Contribution\n\nLes contributions sont les bienvenues ! Veuillez :\n1. Fork le projet\n2. CrÃ©er une branche pour votre fonctionnalitÃ©\n3. Commit vos changements\n4. Push vers la branche\n5. Ouvrir une Pull Request\n\n## ğŸ“ Contact\n\nPour toute question ou suggestion :\n- Email : contact@ninjatech.ai\n- GitHub : https://github.com/ninjatech-ai\n\n---\n\n**Made with â¤ï¸ by NinjaTech AI Team**\n</create-file>\n</function_calls>'}