# ğŸš€ Social Media Sentiment Analysis Tool

Une application SaaS complÃ¨te en Python pour analyser le sentiment des rÃ©seaux sociaux Ã  partir de Twitter, Facebook et Google Reviews.

## ğŸ“‹ FonctionnalitÃ©s

- **Extraction multi-plateformes** : Twitter, Facebook, Google Reviews
- **Analyse de sentiment** : TextBlob + Transformers (modÃ¨les multilingues)
- **Extraction de mots-clÃ©s** : TF-IDF, frÃ©quence, TextRank, combinaison
- **Visualisations** : Graphiques matplotlib, nuages de mots, tableaux de bord
- **Rapports complets** : HTML, CSV, JSON
- **Interface CLI** : Facile Ã  utiliser avec options dÃ©taillÃ©es
- **Support multilingue** : FranÃ§ais et Anglais avec dÃ©tection automatique

## ğŸ› ï¸ Installation

### PrÃ©requis

- Python 3.10 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

### Installation rapide

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/votre-repo/social-media-sentiment-analyzer.git
cd social-media-sentiment-analyzer

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger les donnÃ©es NLTK
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

# Installer spaCy models (optionnel mais recommandÃ©)
python -m spacy download fr_core_news_sm
python -m spacy download en_core_web_sm
```

### Configuration des API

1. **Copier le fichier d'exemple** :
```bash
cp .env.example .env
```

2. **Configurer les clÃ©s API** :
   - **Twitter** : CrÃ©ez une application sur https://developer.twitter.com/
   - **Facebook** : Obtenez un token d'accÃ¨s sur https://developers.facebook.com/
   - **Google** : CrÃ©ez une clÃ© API sur https://console.cloud.google.com/

3. **Ã‰diter le fichier `.env`** avec vos clÃ©s API

## ğŸš€ Utilisation

### Commande de base

```bash
python app.py --service "Uber" --source "twitter" --days 30
```

### Options avancÃ©es

```bash
python app.py --service "Netflix" \
              --source "facebook" \
              --days 15 \
              --max-posts 200 \
              --format html \
              --language fr \
              --sentiment-model transformers \
              --keyword-method combined
```

### ParamÃ¨tres disponibles

| ParamÃ¨tre | Description | DÃ©faut |
|-----------|-------------|---------|
| `--service, -s` | Nom du service/marque Ã  analyser (obligatoire) | - |
| `--source, -src` | Source (twitter/facebook/google_reviews) | twitter |
| `--days, -d` | Nombre de jours Ã  analyser (1-60) | 30 |
| `--max-posts, -m` | Nombre maximum de posts (50-500) | 500 |
| `--output-dir, -o` | RÃ©pertoire de sortie | auto |
| `--format, -f` | Format (csv/json/html/all) | all |
| `--language, -l` | Langue (auto/fr/en) | auto |
| `--sentiment-model, -sm` | ModÃ¨le de sentiment | auto |
| `--keyword-method, -km` | MÃ©thode d'extraction | combined |
| `--verbose, -v` | Mode verbeux | False |
| `--quiet, -q` | Mode silencieux | False |
| `--dry-run` | Simulation sans extraction | False |

## ğŸ“Š Exemples d'utilisation

### Analyse de sentiment pour Uber sur Twitter

```bash
python app.py --service "Uber" --source "twitter" --days 30 --max-posts 500
```

### Analyse dÃ©taillÃ©e avec rapport HTML

```bash
python app.py --service "Airbnb" --source "google_reviews" --days 30 --format html --verbose
```

### Analyse multi-sources

```bash
# Twitter
python app.py -s "Netflix" -src "twitter" -d 30 -m 300

# Facebook
python app.py -s "Netflix" -src "facebook" -d 30 -m 300

# Google Reviews
python app.py -s "Netflix" -src "google_reviews" -d 30 -m 300
```

## ğŸ“ˆ Sorties gÃ©nÃ©rÃ©es

L'application gÃ©nÃ¨re plusieurs types de fichiers :

### Fichiers de donnÃ©es
- `raw_data_[timestamp].csv` : DonnÃ©es brutes extraites
- `processed_data_[timestamp].csv` : DonnÃ©es nettoyÃ©es avec sentiment
- `keywords_[timestamp].csv` : Mots-clÃ©s extraits

### Visualisations
- `sentiment_pie_chart.png` : Camembert des sentiments
- `sentiment_bar_chart.png` : Graphique en barres
- `sentiment_trend_chart.png` : Tendances temporelles
- `keyword_frequency_chart.png` : FrÃ©quence des mots-clÃ©s
- `keyword_score_chart.png` : Score de pertinence
- `analysis_dashboard.png` : Tableau de bord complet

### Nuages de mots
- `keywords_wordcloud.png` : Nuage de mots gÃ©nÃ©ral
- `positive_sentiment_wordcloud.png` : Nuage de mots positifs
- `negative_sentiment_wordcloud.png` : Nuage de mots nÃ©gatifs
- `neutral_sentiment_wordcloud.png` : Nuage de mots neutres

### Rapports
- `report_metadata.json` : MÃ©tadonnÃ©es de l'analyse
- `sentiment_summary.json` : RÃ©sumÃ© des sentiments
- `[service]_[source]_report_[timestamp].html` : Rapport HTML complet

## ğŸ”§ Architecture technique

### Structure du projet

```
social-media-sentiment-analyzer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extractors/          # Modules d'extraction
â”‚   â”‚   â”œâ”€â”€ base_extractor.py
â”‚   â”‚   â”œâ”€â”€ twitter_extractor.py
â”‚   â”‚   â”œâ”€â”€ facebook_extractor.py
â”‚   â”‚   â””â”€â”€ google_reviews_extractor.py
â”‚   â”œâ”€â”€ nlp/                 # Traitement NLP
â”‚   â”‚   â”œâ”€â”€ sentiment_analyzer.py
â”‚   â”‚   â”œâ”€â”€ keyword_extractor.py
â”‚   â”‚   â””â”€â”€ text_preprocessor.py
â”‚   â”œâ”€â”€ visualization/       # Visualisation
â”‚   â”‚   â”œâ”€â”€ charts_generator.py
â”‚   â”‚   â”œâ”€â”€ wordcloud_generator.py
â”‚   â”‚   â””â”€â”€ report_generator.py
â”‚   â”œâ”€â”€ utils/               # Utilitaires
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â”œâ”€â”€ data_validator.py
â”‚   â”‚   â””â”€â”€ file_manager.py
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”œâ”€â”€ main.py              # Orchestration principale
â”‚   â””â”€â”€ cli.py               # Interface CLI
â”œâ”€â”€ data/                    # DonnÃ©es temporaires
â”œâ”€â”€ outputs/                 # RÃ©sultats
â”œâ”€â”€ requirements.txt         # DÃ©pendances
â”œâ”€â”€ app.py                   # Point d'entrÃ©e
â””â”€â”€ setup.py                 # Installation
```

### Technologies utilisÃ©es

- **Extraction** : Tweepy, Facebook SDK, BeautifulSoup, requests
- **NLP** : NLTK, TextBlob, spaCy, Transformers (Hugging Face)
- **Analyse** : scikit-learn, pandas, numpy
- **Visualisation** : matplotlib, seaborn, wordcloud
- **Interface** : Click, colorama, tqdm
- **Configuration** : python-dotenv

## ğŸ¯ MÃ©thodologie

### Analyse de sentiment

1. **PrÃ©traitement** : Nettoyage, normalisation, dÃ©tection de langue
2. **ModÃ¨les utilisÃ©s** :
   - TextBlob (franÃ§ais/anglais)
   - Transformers (RoBERTa multilingue)
3. **Classification** : Positif/NÃ©gatif/Neutre avec score de confiance

### Extraction de mots-clÃ©s

1. **TF-IDF** : Importance relative dans le corpus
2. **FrÃ©quence** : Occurrences brutes
3. **TextRank** : Algorithme basÃ© sur PageRank
4. **Combinaison** : Moyenne pondÃ©rÃ©e des mÃ©thodes

### Validation des donnÃ©es

- Filtrage par longueur minimale
- DÃ©tection et suppression de spam
- Normalisation du texte
- Validation des mÃ©tadonnÃ©es

## âš ï¸ Limites et considÃ©rations

### API Limits
- **Twitter** : 300 requÃªtes/15 minutes
- **Facebook** : 200 requÃªtes/heure
- **Google** : 100 requÃªtes/jour

### Limitations techniques
- DÃ©pend des API disponibles et de leurs restrictions
- L'analyse de sentiment peut varier selon la qualitÃ© du texte
- Les rÃ©sultats sont indicatifs et nÃ©cessitent interprÃ©tation humaine

### ConsidÃ©rations Ã©thiques
- Respect des conditions d'utilisation des plateformes
- Anonymisation des donnÃ©es personnelles
- Usage conforme aux rÃ©glementations (GDPR, etc.)

## ğŸ” DÃ©pannage

### ProblÃ¨mes courants

**Erreur d'authentification API**
```bash
# VÃ©rifiez vos clÃ©s API dans le fichier .env
# Assurez-vous que les clÃ©s sont actives et valides
```

**Pas de donnÃ©es extraites**
```bash
# VÃ©rifiez le nom du service (essayez des variantes)
# RÃ©duisez la pÃ©riode ou augmentez max-posts
# VÃ©rifiez les limites d'API
```

**Erreurs de dÃ©pendances**
```bash
# RÃ©installez les dÃ©pendances
pip install -r requirements.txt --upgrade

# Installez les modÃ¨les spaCy
python -m spacy download fr_core_news_sm
python -m spacy download en_core_web_sm
```

### Support

Pour les problÃ¨mes techniques :
1. VÃ©rifiez les logs dans `outputs/app.log`
2. Activez le mode verbose (`--verbose`)
3. Consultez la documentation des API
4. Ouvrez une issue sur le dÃ©pÃ´t GitHub

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Veuillez :
1. Fork le projet
2. CrÃ©er une branche pour votre fonctionnalitÃ©
3. Commit vos changements
4. Push vers la branche
5. Ouvrir une Pull Request

